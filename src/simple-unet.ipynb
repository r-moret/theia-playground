{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from tensorflow import keras\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Conv2DTranspose,\n",
    "    CenterCrop,\n",
    "    Concatenate,\n",
    ")\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/BRATS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_dimensions_in_classes(segmentation_img: np.array) -> np.array:\n",
    "    segmentation_img = np.multiply(\n",
    "        segmentation_img, np.arange(0, segmentation_img.shape[2])\n",
    "    )\n",
    "    segmentation_img = np.sum(segmentation_img, axis=2)\n",
    "\n",
    "    segmentation_norm = (255.0 / segmentation_img.max()) * (\n",
    "        segmentation_img - segmentation_img.min()\n",
    "    ).astype(int)\n",
    "\n",
    "    return segmentation_norm\n",
    "\n",
    "\n",
    "def plot_image(img_path: str, label_path: str = None):\n",
    "    img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    if label_path:\n",
    "        label = np.load(label_path)\n",
    "        label = unify_dimensions_in_classes(label)\n",
    "        label_masked = np.ma.masked_where(label == 0, label)\n",
    "        plt.imshow(label_masked, cmap=\"Reds\", alpha=0.7)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image = \"2_110\"\n",
    "plot_image(f\"{DATA_FOLDER}/originals/{image}.png\", f\"{DATA_FOLDER}/labels/{image}.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standard_unet(n_classes: int = 2):\n",
    "    # ======================== CONTRACTING PATH ==========================\n",
    "\n",
    "    inputs = Input(shape=(512, 512, 1)) \n",
    "\n",
    "    conv_1_1 = Conv2D(64, 3, padding='same', activation=\"relu\")(inputs)  \n",
    "    conv_1_2 = Conv2D(64, 3, padding='same', activation=\"relu\")(conv_1_1)  \n",
    "\n",
    "    pool_1 = MaxPool2D((2, 2), strides=2)(conv_1_2) \n",
    "\n",
    "    conv_2_1 = Conv2D(128, 3, padding='same', activation=\"relu\")(pool_1)  \n",
    "    conv_2_2 = Conv2D(128, 3, padding='same', activation=\"relu\")(conv_2_1)\n",
    "\n",
    "    pool_2 = MaxPool2D((2, 2), strides=2)(conv_2_2)  \n",
    "\n",
    "    conv_3_1 = Conv2D(256, 3, padding='same', activation=\"relu\")(pool_2) \n",
    "    conv_3_2 = Conv2D(256, 3, padding='same', activation=\"relu\")(conv_3_1) \n",
    "\n",
    "    pool_3 = MaxPool2D((2, 2), strides=2)(conv_3_2)\n",
    "\n",
    "    conv_4_1 = Conv2D(512, 3, padding='same', activation=\"relu\")(pool_3)\n",
    "    conv_4_2 = Conv2D(512, 3, padding='same', activation=\"relu\")(conv_4_1)\n",
    "\n",
    "    pool_4 = MaxPool2D((2, 2), strides=2)(conv_4_2) \n",
    "\n",
    "    conv_5_1 = Conv2D(1024, 3, padding='same', activation=\"relu\")(pool_4)\n",
    "    conv_5_2 = Conv2D(1024, 3, padding='same', activation=\"relu\")(conv_5_1)\n",
    "\n",
    "    # ======================== EXPANDING PATH ============================\n",
    "\n",
    "    up_1 = Conv2DTranspose(512, 2, strides=2, padding=\"same\")(conv_5_2) \n",
    "    conv_4_2_crop = CenterCrop(up_1.shape[1], up_1.shape[2])(conv_4_2)\n",
    "\n",
    "    concat_1 = Concatenate()([up_1, conv_4_2_crop]) \n",
    "    conv_6_1 = Conv2D(512, 3, padding='same', activation=\"relu\")(concat_1)\n",
    "    conv_6_2 = Conv2D(512, 3, padding='same', activation=\"relu\")(conv_6_1)\n",
    "\n",
    "    up_2 = Conv2DTranspose(256, 2, strides=2, padding=\"same\")(conv_6_2) \n",
    "    conv_3_2_crop = CenterCrop(up_2.shape[1], up_2.shape[2])(conv_3_2)  \n",
    "\n",
    "    concat_2 = Concatenate()([up_2, conv_3_2_crop]) \n",
    "    conv_7_1 = Conv2D(256, 3, padding='same', activation=\"relu\")(concat_2)\n",
    "    conv_7_2 = Conv2D(256, 3, padding='same', activation=\"relu\")(conv_7_1) \n",
    "\n",
    "    up_3 = Conv2DTranspose(128, 2, strides=2, padding=\"same\")(conv_7_2)\n",
    "    conv_2_2_crop = CenterCrop(up_3.shape[1], up_3.shape[2])(conv_2_2) \n",
    "\n",
    "    concat_3 = Concatenate()([up_3, conv_2_2_crop]) \n",
    "    conv_8_1 = Conv2D(128, 3, padding='same', activation=\"relu\")(concat_3)\n",
    "    conv_8_2 = Conv2D(128, 3, padding='same', activation=\"relu\")(conv_8_1) \n",
    "\n",
    "    up_4 = Conv2DTranspose(64, 2, strides=2, padding=\"same\")(conv_8_2) \n",
    "    conv_1_2_crop = CenterCrop(up_4.shape[1], up_4.shape[2])(conv_1_2)\n",
    "\n",
    "    concat_4 = Concatenate()([up_4, conv_1_2_crop]) \n",
    "    conv_9_1 = Conv2D(64, 3, padding='same', activation=\"relu\")(concat_4)\n",
    "    conv_9_2 = Conv2D(64, 3, padding='same', activation=\"relu\")(conv_9_1) \n",
    "    conv_9_3 = Conv2D(n_classes, 1, padding='same', activation=\"softmax\")(conv_9_2)\n",
    "\n",
    "    unet = tf.keras.Model(inputs, conv_9_3)\n",
    "    return unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = create_standard_unet(n_classes=5)\n",
    "\n",
    "unet.summary(line_length=130)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(originals_path: str, labels_path: str) -> Tuple[np.array, np.array]:\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    for image_name in tqdm(os.listdir(originals_path)):\n",
    "        label_name = image_name.split('.')[0] + \".npy\"\n",
    "\n",
    "        img = cv.imread(f\"{originals_path}/{image_name}\", cv.IMREAD_GRAYSCALE)\n",
    "        label = np.load(f\"{labels_path}/{label_name}\")\n",
    "\n",
    "        xs.append(img)\n",
    "        ys.append(label)\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    xs = xs.reshape((xs.shape[0], xs.shape[1], xs.shape[2], 1))\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "xs, ys = load_data(f\"{DATA_FOLDER}/originals\", f\"{DATA_FOLDER}/labels\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c35a0ac0e54660a3f6b3415740e3a90cbf569c8b0978327d61e566b03c7762ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
